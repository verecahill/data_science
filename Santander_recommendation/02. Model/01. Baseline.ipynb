{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv('../Dataset/train_ver2.csv/train_ver2.csv')\n",
    "tst = pd.read_csv('../Dataset/test_ver2.csv/test_ver2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상품을 하나도 구매하지 않은 고객 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_product = trn[prods].sum(axis=1) == 0\n",
    "trn = trn[~no_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1375586</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050611</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050612</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050613</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>H</td>\n",
       "      <td>22</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-28</td>\n",
       "      <td>1050614</td>\n",
       "      <td>N</td>\n",
       "      <td>ES</td>\n",
       "      <td>V</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-08-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  fecha_alta  \\\n",
       "0  2015-01-28   1375586            N              ES    H   35  2015-01-12   \n",
       "1  2015-01-28   1050611            N              ES    V   23  2012-08-10   \n",
       "2  2015-01-28   1050612            N              ES    V   23  2012-08-10   \n",
       "3  2015-01-28   1050613            N              ES    H   22  2012-08-10   \n",
       "4  2015-01-28   1050614            N              ES    V   23  2012-08-10   \n",
       "\n",
       "   ind_nuevo antiguedad  indrel  ... ind_hip_fin_ult1 ind_plan_fin_ult1  \\\n",
       "0        0.0          6     1.0  ...                0                 0   \n",
       "1        0.0         35     1.0  ...                0                 0   \n",
       "2        0.0         35     1.0  ...                0                 0   \n",
       "3        0.0         35     1.0  ...                0                 0   \n",
       "4        0.0         35     1.0  ...                0                 0   \n",
       "\n",
       "  ind_pres_fin_ult1 ind_reca_fin_ult1 ind_tjcr_fin_ult1 ind_valo_fin_ult1  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "  ind_viv_fin_ult1 ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "0                0               0                  0                0  \n",
       "1                0               0                  0                0  \n",
       "2                0               0                  0                0  \n",
       "3                0               0                  0                0  \n",
       "4                0               0                  0                0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis=0)\n",
    "\n",
    "features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 범수 label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "features += categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' NA']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val for val in df['age'].unique().astype('str').tolist() if val.endswith('NA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "\n",
    "features += ['age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
    "\n",
    "df.fillna(-99, inplace=True)\n",
    "\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")]\n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns]\n",
    "df_lag['int_date'] += 1\n",
    "\n",
    "df_trn = df.merge(df_lag, on=['ncodpers', 'int_date'], how=\"left\")\n",
    "\n",
    "del df, df_lag\n",
    "\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)\n",
    "\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 학습 : 2016-01-28 ~ 2016.02.28 / 검증 : 2016-05-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dates = ['2016-01-28', '2016-02-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "vld_date = '2016-05-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_valo_fin_ult1_prev</th>\n",
       "      <th>ind_viv_fin_ult1_prev</th>\n",
       "      <th>ind_nomina_ult1_prev</th>\n",
       "      <th>ind_nom_pens_ult1_prev</th>\n",
       "      <th>ind_recibo_ult1_prev</th>\n",
       "      <th>fecha_alta_month_prev</th>\n",
       "      <th>fecha_alta_year_prev</th>\n",
       "      <th>ult_fec_cli_1t_month_prev</th>\n",
       "      <th>ult_fec_cli_1t_year_prev</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10597872</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>194160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2000-09-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7658069</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>1474324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7628180</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>1432311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7628198</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>1432232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7628482</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>1432080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fecha_dato  ncodpers  ind_empleado  pais_residencia  sexo  age  \\\n",
       "10597872  2016-05-28    194160             0                0     0   42   \n",
       "7658069   2016-01-28   1474324             0                0     1   43   \n",
       "7628180   2016-01-28   1432311             0                0     1   26   \n",
       "7628198   2016-01-28   1432232             0                0     1   33   \n",
       "7628482   2016-01-28   1432080             0                0     0   23   \n",
       "\n",
       "          fecha_alta  ind_nuevo  antiguedad  indrel  ...  \\\n",
       "10597872  2000-09-25        0.0         -68     1.0  ...   \n",
       "7658069   2015-10-09        1.0           3     1.0  ...   \n",
       "7628180   2015-08-07        1.0           5     1.0  ...   \n",
       "7628198   2015-08-07        0.0          19     1.0  ...   \n",
       "7628482   2015-08-07        1.0           5     1.0  ...   \n",
       "\n",
       "         ind_valo_fin_ult1_prev  ind_viv_fin_ult1_prev  ind_nomina_ult1_prev  \\\n",
       "10597872                    0.0                    0.0                   0.0   \n",
       "7658069                     0.0                    0.0                   0.0   \n",
       "7628180                     0.0                    0.0                   0.0   \n",
       "7628198                     0.0                    0.0                   0.0   \n",
       "7628482                     0.0                    0.0                   0.0   \n",
       "\n",
       "          ind_nom_pens_ult1_prev  ind_recibo_ult1_prev  fecha_alta_month_prev  \\\n",
       "10597872                     0.0                   0.0                    9.0   \n",
       "7658069                      0.0                   1.0                   10.0   \n",
       "7628180                      0.0                   0.0                  -99.0   \n",
       "7628198                      0.0                   0.0                  -99.0   \n",
       "7628482                      0.0                   0.0                  -99.0   \n",
       "\n",
       "          fecha_alta_year_prev  ult_fec_cli_1t_month_prev  \\\n",
       "10597872                2000.0                        0.0   \n",
       "7658069                 2015.0                        0.0   \n",
       "7628180                  -99.0                      -99.0   \n",
       "7628198                  -99.0                      -99.0   \n",
       "7628482                  -99.0                      -99.0   \n",
       "\n",
       "          ult_fec_cli_1t_year_prev  y  \n",
       "10597872                       0.0  0  \n",
       "7658069                        0.0  1  \n",
       "7628180                      -99.0  2  \n",
       "7628198                      -99.0  2  \n",
       "7628482                      -99.0  2  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost  모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'booster' : 'gbtree',\n",
    "    'max_depth': 8,\n",
    "    'nthread': 4,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'min_child_weight': 10,\n",
    "    'colsmaple_bytree': 0.8,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'seed': 2019\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122825, 105)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37897, 105)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_vld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.86337\teval-mlogloss:1.89301\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:1.66423\teval-mlogloss:1.69168\n",
      "[2]\ttrain-mlogloss:1.53238\teval-mlogloss:1.55829\n",
      "[3]\ttrain-mlogloss:1.43848\teval-mlogloss:1.46318\n",
      "[4]\ttrain-mlogloss:1.36804\teval-mlogloss:1.39287\n",
      "[5]\ttrain-mlogloss:1.31397\teval-mlogloss:1.33838\n",
      "[6]\ttrain-mlogloss:1.27168\teval-mlogloss:1.29697\n",
      "[7]\ttrain-mlogloss:1.23733\teval-mlogloss:1.26367\n",
      "[8]\ttrain-mlogloss:1.20965\teval-mlogloss:1.23646\n",
      "[9]\ttrain-mlogloss:1.18643\teval-mlogloss:1.21464\n",
      "[10]\ttrain-mlogloss:1.16743\teval-mlogloss:1.19714\n",
      "[11]\ttrain-mlogloss:1.15212\teval-mlogloss:1.18275\n",
      "[12]\ttrain-mlogloss:1.13871\teval-mlogloss:1.17056\n",
      "[13]\ttrain-mlogloss:1.12714\teval-mlogloss:1.16057\n",
      "[14]\ttrain-mlogloss:1.11700\teval-mlogloss:1.15249\n",
      "[15]\ttrain-mlogloss:1.10826\teval-mlogloss:1.14543\n",
      "[16]\ttrain-mlogloss:1.10075\teval-mlogloss:1.13964\n",
      "[17]\ttrain-mlogloss:1.09367\teval-mlogloss:1.13477\n",
      "[18]\ttrain-mlogloss:1.08776\teval-mlogloss:1.13039\n",
      "[19]\ttrain-mlogloss:1.08277\teval-mlogloss:1.12676\n",
      "[20]\ttrain-mlogloss:1.07788\teval-mlogloss:1.12391\n",
      "[21]\ttrain-mlogloss:1.07339\teval-mlogloss:1.12121\n",
      "[22]\ttrain-mlogloss:1.06945\teval-mlogloss:1.11917\n",
      "[23]\ttrain-mlogloss:1.06560\teval-mlogloss:1.11698\n",
      "[24]\ttrain-mlogloss:1.06178\teval-mlogloss:1.11509\n",
      "[25]\ttrain-mlogloss:1.05831\teval-mlogloss:1.11353\n",
      "[26]\ttrain-mlogloss:1.05558\teval-mlogloss:1.11229\n",
      "[27]\ttrain-mlogloss:1.05298\teval-mlogloss:1.11119\n",
      "[28]\ttrain-mlogloss:1.05023\teval-mlogloss:1.11040\n",
      "[29]\ttrain-mlogloss:1.04730\teval-mlogloss:1.10962\n",
      "[30]\ttrain-mlogloss:1.04434\teval-mlogloss:1.10873\n",
      "[31]\ttrain-mlogloss:1.04205\teval-mlogloss:1.10813\n",
      "[32]\ttrain-mlogloss:1.03945\teval-mlogloss:1.10777\n",
      "[33]\ttrain-mlogloss:1.03727\teval-mlogloss:1.10724\n",
      "[34]\ttrain-mlogloss:1.03470\teval-mlogloss:1.10698\n",
      "[35]\ttrain-mlogloss:1.03254\teval-mlogloss:1.10665\n",
      "[36]\ttrain-mlogloss:1.03006\teval-mlogloss:1.10635\n",
      "[37]\ttrain-mlogloss:1.02811\teval-mlogloss:1.10612\n",
      "[38]\ttrain-mlogloss:1.02607\teval-mlogloss:1.10600\n",
      "[39]\ttrain-mlogloss:1.02367\teval-mlogloss:1.10587\n",
      "[40]\ttrain-mlogloss:1.02061\teval-mlogloss:1.10570\n",
      "[41]\ttrain-mlogloss:1.01855\teval-mlogloss:1.10568\n",
      "[42]\ttrain-mlogloss:1.01576\teval-mlogloss:1.10556\n",
      "[43]\ttrain-mlogloss:1.01367\teval-mlogloss:1.10533\n",
      "[44]\ttrain-mlogloss:1.01171\teval-mlogloss:1.10539\n",
      "[45]\ttrain-mlogloss:1.00931\teval-mlogloss:1.10516\n",
      "[46]\ttrain-mlogloss:1.00644\teval-mlogloss:1.10507\n",
      "[47]\ttrain-mlogloss:1.00439\teval-mlogloss:1.10526\n",
      "[48]\ttrain-mlogloss:1.00182\teval-mlogloss:1.10526\n",
      "[49]\ttrain-mlogloss:0.99923\teval-mlogloss:1.10533\n",
      "[50]\ttrain-mlogloss:0.99778\teval-mlogloss:1.10546\n",
      "[51]\ttrain-mlogloss:0.99577\teval-mlogloss:1.10555\n",
      "[52]\ttrain-mlogloss:0.99425\teval-mlogloss:1.10549\n",
      "[53]\ttrain-mlogloss:0.99194\teval-mlogloss:1.10536\n",
      "[54]\ttrain-mlogloss:0.98997\teval-mlogloss:1.10540\n",
      "[55]\ttrain-mlogloss:0.98818\teval-mlogloss:1.10563\n",
      "[56]\ttrain-mlogloss:0.98588\teval-mlogloss:1.10572\n",
      "[57]\ttrain-mlogloss:0.98375\teval-mlogloss:1.10565\n",
      "[58]\ttrain-mlogloss:0.98150\teval-mlogloss:1.10579\n",
      "[59]\ttrain-mlogloss:0.97933\teval-mlogloss:1.10598\n",
      "[60]\ttrain-mlogloss:0.97729\teval-mlogloss:1.10602\n",
      "[61]\ttrain-mlogloss:0.97525\teval-mlogloss:1.10611\n",
      "[62]\ttrain-mlogloss:0.97294\teval-mlogloss:1.10640\n",
      "[63]\ttrain-mlogloss:0.97057\teval-mlogloss:1.10643\n",
      "[64]\ttrain-mlogloss:0.96882\teval-mlogloss:1.10647\n",
      "[65]\ttrain-mlogloss:0.96711\teval-mlogloss:1.10662\n",
      "[66]\ttrain-mlogloss:0.96536\teval-mlogloss:1.10664\n",
      "Stopping. Best iteration:\n",
      "[46]\ttrain-mlogloss:1.00644\teval-mlogloss:1.10507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn= xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 검증 MAP@7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "        \n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    \n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "            \n",
    "    if not actual:\n",
    "        return default\n",
    "    \n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04266379915553903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036307454166184965\n"
     ]
    }
   ],
   "source": [
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
    "\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]\n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1\n",
    "            \n",
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))\n",
    "\n",
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
    "\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p,ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y, p, ip in y_prods])\n",
    "    \n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.86308\n",
      "[1]\ttrain-mlogloss:1.66298\n",
      "[2]\ttrain-mlogloss:1.53061\n",
      "[3]\ttrain-mlogloss:1.43589\n",
      "[4]\ttrain-mlogloss:1.36584\n",
      "[5]\ttrain-mlogloss:1.31136\n",
      "[6]\ttrain-mlogloss:1.26909\n",
      "[7]\ttrain-mlogloss:1.23529\n",
      "[8]\ttrain-mlogloss:1.20787\n",
      "[9]\ttrain-mlogloss:1.18543\n",
      "[10]\ttrain-mlogloss:1.16689\n",
      "[11]\ttrain-mlogloss:1.15109\n",
      "[12]\ttrain-mlogloss:1.13837\n",
      "[13]\ttrain-mlogloss:1.12708\n",
      "[14]\ttrain-mlogloss:1.11743\n",
      "[15]\ttrain-mlogloss:1.10918\n",
      "[16]\ttrain-mlogloss:1.10147\n",
      "[17]\ttrain-mlogloss:1.09484\n",
      "[18]\ttrain-mlogloss:1.08935\n",
      "[19]\ttrain-mlogloss:1.08440\n",
      "[20]\ttrain-mlogloss:1.07962\n",
      "[21]\ttrain-mlogloss:1.07567\n",
      "[22]\ttrain-mlogloss:1.07188\n",
      "[23]\ttrain-mlogloss:1.06809\n",
      "[24]\ttrain-mlogloss:1.06505\n",
      "[25]\ttrain-mlogloss:1.06230\n",
      "[26]\ttrain-mlogloss:1.05959\n",
      "[27]\ttrain-mlogloss:1.05743\n",
      "[28]\ttrain-mlogloss:1.05455\n",
      "[29]\ttrain-mlogloss:1.05206\n",
      "[30]\ttrain-mlogloss:1.04965\n",
      "[31]\ttrain-mlogloss:1.04736\n",
      "[32]\ttrain-mlogloss:1.04536\n",
      "[33]\ttrain-mlogloss:1.04314\n",
      "[34]\ttrain-mlogloss:1.04090\n",
      "[35]\ttrain-mlogloss:1.03902\n",
      "[36]\ttrain-mlogloss:1.03667\n",
      "[37]\ttrain-mlogloss:1.03431\n",
      "[38]\ttrain-mlogloss:1.03216\n",
      "[39]\ttrain-mlogloss:1.02981\n",
      "[40]\ttrain-mlogloss:1.02806\n",
      "[41]\ttrain-mlogloss:1.02577\n",
      "[42]\ttrain-mlogloss:1.02371\n",
      "[43]\ttrain-mlogloss:1.02153\n",
      "[44]\ttrain-mlogloss:1.01955\n",
      "[45]\ttrain-mlogloss:1.01780\n",
      "[46]\ttrain-mlogloss:1.01612\n",
      "[47]\ttrain-mlogloss:1.01422\n",
      "[48]\ttrain-mlogloss:1.01180\n",
      "[49]\ttrain-mlogloss:1.00968\n",
      "[50]\ttrain-mlogloss:1.00753\n",
      "[51]\ttrain-mlogloss:1.00564\n",
      "[52]\ttrain-mlogloss:1.00369\n",
      "[53]\ttrain-mlogloss:1.00173\n",
      "[54]\ttrain-mlogloss:1.00010\n",
      "[55]\ttrain-mlogloss:0.99808\n",
      "[56]\ttrain-mlogloss:0.99587\n",
      "[57]\ttrain-mlogloss:0.99409\n",
      "[58]\ttrain-mlogloss:0.99234\n",
      "[59]\ttrain-mlogloss:0.99054\n",
      "[60]\ttrain-mlogloss:0.98903\n",
      "Feature importance:\n",
      "('renta', 5185)\n",
      "('age', 4717)\n",
      "('antiguedad', 4331)\n",
      "('fecha_alta_month', 3076)\n",
      "('age_prev', 2860)\n",
      "('antiguedad_prev', 2701)\n",
      "('nomprov', 2661)\n",
      "('fecha_alta_year', 2440)\n",
      "('canal_entrada', 1901)\n",
      "('renta_prev', 1415)\n",
      "('nomprov_prev', 1378)\n",
      "('canal_entrada_prev', 990)\n",
      "('ind_recibo_ult1_prev', 940)\n",
      "('sexo', 879)\n",
      "('ind_cno_fin_ult1_prev', 859)\n",
      "('ind_ecue_fin_ult1_prev', 853)\n",
      "('ind_cco_fin_ult1_prev', 852)\n",
      "('fecha_alta_month_prev', 638)\n",
      "('ind_reca_fin_ult1_prev', 542)\n",
      "('ind_tjcr_fin_ult1_prev', 528)\n",
      "('fecha_alta_year_prev', 517)\n",
      "('ind_nom_pens_ult1_prev', 496)\n",
      "('segmento', 489)\n",
      "('segmento_prev', 467)\n",
      "('ind_ctop_fin_ult1_prev', 407)\n",
      "('ind_dela_fin_ult1_prev', 402)\n",
      "('ind_valo_fin_ult1_prev', 400)\n",
      "('ind_nomina_ult1_prev', 400)\n",
      "('tiprel_1mes', 392)\n",
      "('ind_actividad_cliente', 326)\n",
      "('ind_ctpp_fin_ult1_prev', 305)\n",
      "('tiprel_1mes_prev', 303)\n",
      "('ind_fond_fin_ult1_prev', 272)\n",
      "('ind_ctma_fin_ult1_prev', 259)\n",
      "('ind_actividad_cliente_prev', 218)\n",
      "('sexo_prev', 215)\n",
      "('indext', 199)\n",
      "('ind_nuevo', 198)\n",
      "('ind_plan_fin_ult1_prev', 129)\n",
      "('ind_deco_fin_ult1_prev', 120)\n",
      "('ind_nuevo_prev', 120)\n",
      "('ind_hip_fin_ult1_prev', 116)\n",
      "('indext_prev', 76)\n",
      "('indrel_1mes', 57)\n",
      "('pais_residencia', 53)\n",
      "('ind_empleado_prev', 34)\n",
      "('ind_viv_fin_ult1_prev', 28)\n",
      "('ind_empleado', 27)\n",
      "('ind_ctju_fin_ult1_prev', 24)\n",
      "('indrel_1mes_prev', 21)\n",
      "('pais_residencia_prev', 20)\n",
      "('indfall', 15)\n",
      "('ind_pres_fin_ult1_prev', 15)\n",
      "('ind_deme_fin_ult1_prev', 14)\n",
      "('indrel', 13)\n",
      "('ult_fec_cli_1t_month', 2)\n",
      "('indresi_prev', 2)\n",
      "('ind_cder_fin_ult1_prev', 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, tuple found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-d40ea2ac4047>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0my_prods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mip\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0my_prods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0msubmit_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{},{}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncodper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_prods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, tuple found"
     ]
    }
   ],
   "source": [
    "X_all = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names = features)\n",
    "watch_list = [(dall, 'train')]\n",
    "\n",
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
    "\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k, v) for k, v in model.get_fscore().items()], key=lambda kv:kv[1], reverse=True):\n",
    "    print(kv)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "E:\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst= preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file = open('./xgb.baseline.2015-06-28', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y, p, ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./xgb.baseline_predict', 'w') as f:\n",
    "    f.write('ncodpers,added_products\\n')\n",
    "    for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "        y_prods = [(y,p,ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
    "        y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "        y_prods = [p for y, p, ip in y_prods]\n",
    "        f.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = pd.read_csv('./xgb.baseline_predict')\n",
    "baseline.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning] *",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
